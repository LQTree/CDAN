# ablation_evaluation_fixed.py - ä¿®å¤Windowså…¼å®¹æ€§é—®é¢˜
import os
import sys
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, f1_score, classification_report
from tqdm import tqdm


sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from cdan_model import CDAN
from data_preprocess import MVSAImageTextDataset, DataLoader, transforms

# ==================== å…¨å±€å®šä¹‰ FixedValDatasetï¼ˆå…³é”®ä¿®å¤ï¼‰ ====================
class FixedValDataset(MVSAImageTextDataset):
    """å¯pickleçš„å›ºå®šéªŒè¯é›†Datasetï¼ˆå…¨å±€ç±»ï¼‰"""
    def __init__(self, data_dir, guid_list, label_map=None):
        self.data_dir = data_dir
        self.guid_list = guid_list
        self.max_text_len = 128
        self.mode = 'val'
        
        # å›¾åƒé¢„å¤„ç†ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])
        
        # æ ‡ç­¾æ˜ å°„
        self.label_map = label_map or {'positive': 0, 'neutral': 1, 'negative': 2}
        self.reverse_label_map = {v: k for k, v in self.label_map.items()}
        
        # ä»æ ‡ç­¾æ–‡ä»¶åŠ è½½å®Œæ•´df
        label_file = r"E:\data\project5\project5\train.txt"  # æ›¿æ¢ä¸ºä½ çš„å®é™…è·¯å¾„
        full_df = pd.read_csv(label_file)
        
        # è¿‡æ»¤å‡ºéªŒè¯é›†æ ·æœ¬
        self.df = full_df[full_df['guid'].isin(guid_list)].reset_index(drop=True)
        
        # ç”Ÿæˆæ ‡ç­¾
        valid_mask = self.df['tag'].isin(self.label_map.keys())
        self.df = self.df[valid_mask].reset_index(drop=True)
        self.labels = self.df['tag'].map(self.label_map).values.astype(np.int64)
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        guid = int(self.df.iloc[idx]['guid'])
        img_path = os.path.join(self.data_dir, f"{guid}.jpg")
        txt_path = os.path.join(self.data_dir, f"{guid}.txt")
        
        # åŠ è½½å›¾åƒ
        from PIL import Image
        try:
            image = Image.open(img_path).convert('RGB')
            image = self.transform(image)
        except Exception as e:
            print(f"å›¾åƒåŠ è½½å¤±è´¥ {img_path}: {e}")
            image = torch.zeros(3, 224, 224)
        
        # åŠ è½½æ–‡æœ¬
        try:
            with open(txt_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read().strip()
            import re
            text = re.sub(r'http\S+|www\S+', '', text)
            text = re.sub(r'@\w+|#\w+', '', text)
            text = re.sub(r'\s+', ' ', text).strip()
            if len(text) > 200:
                text = text[:200] + "..."
            if not text:
                text = "[EMPTY]"
        except Exception as e:
            print(f"æ–‡æœ¬åŠ è½½å¤±è´¥ {txt_path}: {e}")
            text = "[ERROR]"
        
        return {
            'guid': guid,
            'image': image,
            'text': text[:self.max_text_len],
            'label': torch.tensor(self.labels[idx], dtype=torch.long)
        }

# ==================== é…ç½® ====================
CONFIG = {
    'model_path': r'E:\data\project5\project5\output\best_model.pth',
    'val_guid_file': r'E:\data\project5\project5\output\val_guids.csv',
    'data_dir': r'E:\data\project5\project5\data',
    'clip_path': r'E:\data\project5\project5\clip',
    'bert_path': r'E:\data\project5\project5\bert',
    'vit_path': r'E:\data\project5\project5\vit',
    'batch_size': 32,
    'num_workers': 0  # Windowså¿…é¡»è®¾ä¸º0é¿å…pickleé—®é¢˜
}

def set_seed(seed=42):
    import random
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def load_model(config):
    """åŠ è½½å·²è®­ç»ƒCDANæ¨¡å‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"[è®¾å¤‡] ä½¿ç”¨ {device}")
    
    model = CDAN(
        num_classes=3,
        feat_dim=512,
        cmsa_layers=8,
        cmsa_heads=8,
        config=config
    ).to(device)
    
    # åŠ è½½æƒé‡
    try:
        checkpoint = torch.load(config['model_path'], map_location=device, weights_only=False)
    except TypeError:
        checkpoint = torch.load(config['model_path'], map_location=device)
    
    state_dict = checkpoint['model_state_dict']
    if list(state_dict.keys())[0].startswith('module.'):
        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict)
    model.eval()
    
    print(f"[æ¨¡å‹] åŠ è½½æˆåŠŸ | æœ€ä½³éªŒè¯ACC: {checkpoint.get('best_val_acc', 'N/A'):.2f}%")
    return model, device

def create_fixed_val_loader(data_dir, val_guid_file, batch_size=32, num_workers=0):
    """åˆ›å»ºå›ºå®šéªŒè¯é›†DataLoader"""
    # è¯»å–GUID
    val_df = pd.read_csv(val_guid_file)
    guid_list = val_df['guid'].tolist()
    label_list = val_df['label'].tolist() if 'label' in val_df.columns else None
    
    # åˆ›å»ºDataset
    dataset = FixedValDataset(data_dir, guid_list)
    
    # åˆ›å»ºDataLoader
    loader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,  # Windowså¿…é¡»=0
        pin_memory=True if torch.cuda.is_available() else False
    )
    
    print(f"[æ•°æ®] å›ºå®šéªŒè¯é›†åŠ è½½å®Œæˆ | æ ·æœ¬æ•°: {len(dataset)}")
    return loader, label_list

@torch.no_grad()
def evaluate_full(model, device, val_loader, val_labels):
    """å®Œæ•´CDANæ¨¡å‹è¯„ä¼°"""
    print("\n[è¯„ä¼°] CDAN Full Model")
    preds = []
    pbar = tqdm(val_loader, desc="Full Model", ncols=80)
    
    for batch in pbar:
        images = batch['image'].to(device)
        texts = batch['text']
        outputs = model(images, texts)
        preds.extend(torch.argmax(outputs['logits'], dim=1).cpu().numpy())
    
    acc = accuracy_score(val_labels, preds) * 100
    f1 = f1_score(val_labels, preds, average='weighted') * 100
    
    print(f"\nâœ… CDAN Full è¯„ä¼°ç»“æœ:")
    print(f"   Accuracy: {acc:.2f}%")
    print(f"   Weighted F1: {f1:.2f}%")
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(val_labels, preds, 
                              target_names=['positive', 'neutral', 'negative']))
    return acc, f1

def main():
    set_seed(1)  # ä¸train.pyä¸€è‡´
    
    print("="*60)
    print("CDAN æ¶ˆèå®éªŒï¼ˆä½¿ç”¨å›ºå®šéªŒè¯é›†ï¼‰")
    print("="*60)
    
    # 1. åŠ è½½æ¨¡å‹
    model, device = load_model(CONFIG)
    
    # 2. åŠ è½½å›ºå®šéªŒè¯é›†
    val_loader, val_labels = create_fixed_val_loader(
        CONFIG['data_dir'],
        CONFIG['val_guid_file'],
        batch_size=CONFIG['batch_size'],
        num_workers=CONFIG['num_workers']  # Windows=0
    )
    
    # 3. è¯„ä¼°å®Œæ•´æ¨¡å‹
    acc_full, f1_full = evaluate_full(model, device, val_loader, val_labels)
    
    print("\n" + "="*60)
    print("æ¶ˆèå®éªŒç»“æœæ±‡æ€»")
    print("="*60)
    print(f"{'æ¨¡å¼':<20} | {'Accuracy':<12} | {'Weighted F1':<12}")
    print("-"*60)
    print(f"{'CDAN Full':<20} | {acc_full:>10.2f}% | {f1_full:>12.2f}%")
    print("="*60)
    
    # ä¿å­˜ç»“æœ
    result = pd.DataFrame([{
        'mode': 'CDAN Full',
        'accuracy': acc_full,
        'f1': f1_full
    }])
    result.to_csv(os.path.join(os.path.dirname(CONFIG['model_path']), 'ablation_results.csv'), index=False)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {os.path.join(os.path.dirname(CONFIG['model_path']), 'ablation_results.csv')}")

if __name__ == "__main__":
    main()